<?php
$title="Linear Algebra for the 21st&nbsp;century --- reformed for modern applications";
$thisfile=__FILE__;
include "header.php";
include "menuside.php";
?>

<div class="newspaper">

<img src="Share/9780198856405.jpg" width=120
align="left" style="margin: 0px 10px 5px 0px;" />

Get the book <em>Linear Algebra for the
21st&nbsp;Century</em> via either <a
href="https://global.oup.com/academic/product/linear-algebra-for-the-21st-century-9780198856405?cc=us&lang=en&">
Oxford University Press</a>, or via <a
href="https://www.amazon.com/gp/product/0198856407/ref=dbs_a_def_rwt_bibl_vppi_i1">
Amazon</a>.

<p><!--<h3>Brief description</h3>-->
This book establishes a new route through linear algebra,
one that develops early the Singular Value
Decomposition&nbsp;(SVD), the so-called "jewel in crown" of
linear algebra. Thereafter the beautiful power of the SVD
both explores many modern applications, especially in Data
Science, and also develops traditional linear algebra
concepts, theory, and methods.  No rigour is lost in this
new route: indeed, this book demonstrates that most theory
is better proved with an SVD rather than with a traditional
approach.  This new route through linear algebra becomes
available by the ready availability of ubiquitous computing
in the 21st&nbsp;century.


<h2>Three important features</h2>
<DL><DT>
Integrates the availability of ubiquitous computing into linear algebra.
</DT><DD>
This meets the demands made in recent national reviews of
undergraduate mathematics curricula (e.g., 
<a href="http://sefi.htw-aalen.de/curriculum.htm">Alpers et al. 2013</a>, &nbsp; 
<a href="https://doi.org/10.1090/noti1106">Bressoud et al. 2014</a>, &nbsp;
<a href="http://www.siam.org/reports/ModelingAcross Curr_2014.pdf">Turner et al. 2015</a>, &nbsp;
<a href="http://www.maa.org/programs/faculty-and-departments/curriculum-department-guidelines-recommendations/cupm">Schumacher
et al. 2015</a>, &nbsp;
<a href="http://www.siam.org/reports/gaimme.php?_ga=1">Bliss et al. 2016</a>&nbsp;)
</DD><DT>
Reforms/reshapes linear algebra to best suit 21st century
teaching, theory and application.
</DT><DD>
This is especially suitable for the so-called `big data' of
bioinformatics, data mining, image processing, and
artificial intelligence.
</DD><DT>
The Singular Value Decomposition (SVD) is a key enabling tool.
</DT><DD>
The SVD is sometimes called the jewel in the crown of linear
algebra.  Limitations of traditional by-hand methods make
the SVD inaccessible, but with ubiquitous computing this
book utilises its power for both applications and theory.
</DD></DL>



<h2>The future of linear algebra</h2>

The book is aimed for students in the first year or two of
university study of the mathematics of linear algebra for
science, engineering or computing.  It also forms an ideal
companion to supplement modern statistics courses.  Much of
the design of traditional mathematics curricula was
predicated on `by hand' calculation.  Ubiquitous computing
via laptops, iPads and smart-phones requires us to refresh
what we teach and how it is taught, especially as computing
has become the `third arm' of engineering and science.  This
book reforms linear algebra to best suit 21st century
teaching and application, especially for the so-called `big
data' of bioinformatics, data mining, image processing, and
artificial intelligence.  Just as importantly, this reform
improves the learning of the theory of linear algebra. 
</P>

With ubiquitous computing the approach to linear algebra
needs to be reimagined.   Recent national reviews of
curricula identified the need (Alpers et al. 2013, Bressoud
et al. 2014, Turner et al. 2015, Schumacher et al. 2015,
Bliss et al. 2016, e.g.), and this book answers the call. 
Modern applications of linear algebra, especially in the
rapidly broadening fields of Data Mining and Artificial
Intelligence, and also in fields such as Bioinformatics,
require the Singular Value Decomposition (SVD).  This book
places the SVD central and early to empower the students in
these disciplines to learn and use the best techniques. 
Indeed the SVD is sometimes called the jewel in the crown of
linear algebra, and this book makes its power available
early and broadly to students and courses.  No rigour is
lost in this new route: indeed, this book demonstrates that
most theory is better proved with an SVD. 
</P>

Additionally, there is earlier introduction, development and
emphasis on orthogonality that is vital in so many applied
disciplines throughout science, engineering, computing and
increasingly social sciences. A strong graphical emphasis
takes advantage of the power of visualisation in the human
brain.  Examples throughout include modern applications such
as GPS, text mining, image processing.  Active learning
exercises throughout are aimed to enhance lectures, quizzes,
or `flipped' teaching.


<!--
<blockquote>
Traditional courses in linear algebra make considerable use
of the reduced row echelon form (<small>RREF</small>), but
the <small>RREF</small> is an unreliable tool for
computation in the face of inexact data and arithmetic. The
[Singular Value Decomposition] <small>SVD</small> can be
regarded as a modern, computationally powerful replacement
for the <small>RREF</small>.
&nbsp; &nbsp; &nbsp; <a href="http://au.mathworks.com/company/newsletters/articles/professor-svd.html">(Cleve Moler, MathWorks, 2006)</a>
</blockquote>

The Singular Value Decomposition (<small>SVD</small>) is
sometimes called the <em>jewel in the crown</em> of linear
algebra. Traditionally the <small>SVD</small> was introduced
and explored at the end of several linear algebra courses.
Question: Why were students required to wait until the end of
the course to be introduced to beauty and power of this
jewel? Answer: limitations of hand calculation. 
<p>
This book
establishes a new route through linear algebra, one that
reaches the <small>SVD</small> jewel in linear algebra's
crown very early. Thereafter its beautiful power explores
many modern applications and also develops traditional
linear algebra concepts, theory, and methods. No rigour is
lost in this new route: indeed, this book demonstrates that
most theory is better proved with an <small>SVD</small>
rather than with the traditional <small>RREF</small>. 
Such a new route through linear algebra becomes available by the ready availability of ubiquitous computing in the 21st century.
-->

<blockquote>
As so many other disciplines use the <small>SVD</small>, it
is not only important that mathematicians understand what it
is, but also teach it thoroughly in linear algebra
&nbsp; &nbsp; &nbsp; <a href="http://www.siam.org/reports/modeling_14.pdf">(Turner et al., 2015, p.30)</a>
</blockquote>






<h2>LaTeX sources for graphic exercises</h2>
To help teachers generate good graphical questions, here are
links to LaTeX source code for generating graphical
exercises corresponding to ones in the book.
<ol><li><b>Vectors</b>
    <ul><li>None.
    </li></ul>
    
</li><li><b>Systems of linear equations</b>
    <ul><li><a href="GraphicExercises/2-1-2.tex">
        2.1.2 estimate the equations of the pair of lines ...</a>
    </li><li><a href="GraphicExercises/2-3-1.tex">
        2.3.1 express vectors as a linear combination ...</a>
    </li><li><a href="GraphicExercises/2-3-2.tex">
        2.3.2 write down a parametric equation of the line ...</a>
    </li></ul>
    
</li><li><b>Matrices encode system interactions</b>
    <ul><li><a href="GraphicExercises/3-2-11.tex">
        3.2.11 which appear to correspond to multiplication by a diagonal matrix ...</a>
    </li><li><a href="GraphicExercises/3-2-12.tex">
        3.2.12 which appear to correspond to multiplication by a diagonal matrix ...</a>
    </li><li><a href="GraphicExercises/3-2-13.tex">
        3.2.13 Draw approximate orthogonal coordinate axes ...</a>
    </li><li><a href="GraphicExercises/3-2-15.tex">
        3.2.15 vectors appear to form an orthogonal set ...</a>
    </li><li><a href="GraphicExercises/3-2-16.tex">
        3.2.16 vectors appear to form an orthogonal set ...</a>
    </li><li><a href="GraphicExercises/3-2-24.tex">
        3.2.24 which appear to be that of multiplying by an orthogonal matrix ...</a>
    </li><li><a href="GraphicExercises/3-2-25.tex">
        3.2.25 which appear to be that of multiplying by an orthogonal matrix ...</a>
    </li><li><a href="GraphicExercises/3-5-21.tex">
        3.5.21 draw the orthogonal projection ...</a>
    </li><li><a href="GraphicExercises/3-5-28.tex">
        3.5.28 draw its orthogonal complement ...</a>
    </li><li><a href="GraphicExercises/3-5-31.tex">
        3.5.31 draw the decomposition of a vector into the sum ...</a>
    </li><li><a href="GraphicExercises/3-6-1.tex">
        3.6.1 which cannot be that of a linear transformation ...</a>
    </li><li><a href="GraphicExercises/3-6-3.tex">
        3.6.3 which cannot be that of a linear transformation ...</a>
    </li><li><a href="GraphicExercises/3-6-18.tex">
        3.6.18 estimate the standard matrix of the linear transformation ...</a>
    </li></ul>

</li><li><b>Eigenvalues and eigenvectors of symmetric matrices</b>
    <ul><li><a href="GraphicExercises/4-1-1.tex">
        4.1.1 which directions are eigenvectors ...</a>
    </li><li><a href="GraphicExercises/4-1-8.tex">
        4.1.8 eigenvalues of an adjacency matrix ...</a>
    </li><li><a href="GraphicExercises/4-2-1.tex">
        4.2.1 estimate if the matrix is invertible ...</a>
    </li><li><a href="GraphicExercises/4-2-16.tex">
        4.2.16 draw coordinate axes for a coordinate system ...</a>
    </li></ul>

</li><li><b>Approximate matrices</b>
    <ul><li><a href="GraphicExercises/5-1-1.tex">
        5.1.1 roughly estimate the norm of the matrix ...</a>
    </li><li><a href="GraphicExercises/5-1-5.tex">
        5.1.5 Compute an SVD of the pixel image ...</a>
    </li></ul>

</li><li><b>Determinants distinguish matrices</b>
    <ul><li><a href="GraphicExercises/6-1-1.tex">
        6.1.1 guesstimate by eye the determinant ...</a>
    </li><li><a href="GraphicExercises/6-1-3.tex">
        6.1.3 estimate the matrix of the linear transformation, and its determinant ...</a>
    </li></ul>

</li><li><b>Eigenvalues and eigenvectors in general</b>
    <ul><li><a href="GraphicExercises/7-0-1.tex">
        7.0.1 does the matrix have real eigenvalues, or complex ...</a>
    </li><li><a href="GraphicExercises/7-2-10.tex">
        7.2.10 estimate the components the vectors in the shown basis ...</a>
    </li></ul>

</li></ol>






</div>
<small>
<?php 
include "footer.php";
?>